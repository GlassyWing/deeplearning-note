# 度量和其它公式

## 度量

### 均方误差(MSE)

$$ \frac{1}{m} \sum_{i=1}^m(y_i - \hat{y_i})^2 $$

### 根均方误差(RMSE)

$$ \sqrt{ \frac{1}{m} \sum_{i=1}^m(y_i - \hat{y_i})^2} $$

### 平均绝对误差(MAE)

$$ \frac{1}{m} \sum_{i=1}^m|y_i - \hat{y_i}| $$

## 范数

### L1范数

$$ \|x\| = \sum|x| $$

L1范数是指向量中各个元素的绝对值之和

### L2范数

$$ \|x\| = \sqrt{\sum(x^2)} $$

L2范数是指向量各元素的平方和然后开方

## 熵

熵的本质是香农信息量$log\frac{1}{p}  $的期望：

$$ H(p)=\sum_{i}^{} p(i)*log_2\frac{1}{p(i)}  $$

### 交叉熵

交叉熵衡量了在使用非真实分布的策略下消除系统不确定性所需花费的最小努力。

$$ H(p,q)=\sum_{i}^{} p(i)*log_2\frac{1}{q(i)}  $$

### 相对熵(KL散度)

相对熵衡量不同策略之间的差异，用来衡量两个取值为正的函数或概率分布之间的差异，即：

$$ KL（p || q） = H(p,q) - H(p) =  \sum_{k=1}^N p_k \log_2 \frac{1}{q_k} - \sum_{k=1}^N p_k \log_2 \frac{1}{p_k} = \sum_{k=1}^N p_k \log_2 \frac{p_k}{q_k} $$