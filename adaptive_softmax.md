# Adaptive Softmax

自适应Softmax

## 提出原因

原来的分层Softmax只使用于CPU，并不适用于GPU

## 基本原理

根据2-8原则，即80%的文档中只包含20%的单词，或者说20%的单词覆盖了80%的文档，设想下面的场景：

假设有1000个单词构成的词汇表，其中200个为常用词，且任意一个单词，它为常用词的概率80%。那么将词汇表按常用和非常用进行分组后，计算次数的期望为200 x 80% + 800 x 20% = 320。而原始的Softmax需要计算1000次。则分组后，计算速度提升了将近4倍！

那么处理词汇表的基本思路如下：

1. 将词汇表分割为两组 $V^{HEAD}$ 和 $V^{TAIL}$
2. 将少一些的更常出现的单词放入$V^{HEAD}$, 其它单词放入$V^{TAIL}$，那么任意一个单词出现在$V^{HEAD}$中的概率显然更大，即$p(V^{HEAD}) > p(V^{TAIL})$

## 处理步骤

1. 首先将$V^{TAIL}$，从原词汇表中剔除，并新增一个分类用来指代原来属于$V^{TAIL}$中的词，那么现在词汇表的数量为$V^{HEAD} + 1$
2. 首先在现有的词汇表上做一次Softmax，若单词属于$V^{TAIL}$, 唯一需要做的就是在$V^{TAIL}$中再做一次Softmax。那么单词的概率变为了 $P^{HEAD}(tail|h) * P^{TAIL}(w|h)$,$P^{HEAD}(tail|h)$指单词属于$V^{TAIL}$的概率，而后者指单词是$V^{TAIL}$中任意单词的概率。

然而，你并非只能分为两组，更常用的是分为2-5组，处理方式与2组的相似，以5组为例：

1. 首先将原词汇表进行划分，使其数量为$V^{HEAD} + 4$，其余4类代表单词属于其它分组的概率
2. 然后按照2组时的第二步相同

## 提升推理速度的另一个Trick

另一个以最小的精度牺牲提高速度的方法，就是为每个组都赋予不同的容量。设$nh$为模型隐层的输出维度，对于更常用的单词，需要更大的容量来使预测更准确。假设1000个单词，被[200, 400]分为3组，那么前200个单词用$nh$进行预测，200-400个单词可以$nh / 2$的容量进行预测，剩余的单词可以$nh / 4$的容量进行预测。